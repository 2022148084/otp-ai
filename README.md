# 🚀 Kakao OCR & Video Analysis Service (Modal MLOps)

이 프로젝트는 카카오톡 스크린샷 이미지와 스크롤 녹화 동영상을 분석하여 텍스트로 변환하는 AI 마이크로서비스입니다.  
**OCI(Oracle Cloud)** 백엔드와 연동되며, 무거운 AI 연산(SpyNet, PaddleOCR)은 **Modal(Serverless GPU)** 위에서 실행됩니다.

---

## 🛠️ 개발 환경 설정 (팀원용 퀵 가이드)

🚨 **주의:** 로컬 맥북에 `torch`, `paddlepaddle` 등 무거운 라이브러리를 **절대 설치하지 마세요.**  
모든 연산은 클라우드 GPU에서 수행됩니다. 로컬에는 오직 `modal` 클라이언트만 있으면 됩니다.

### 1. 프로젝트 클론 및 가상환경 설정

터미널을 열고 순서대로 입력하세요.

```bash
# 1. 저장소 클론 (이미 받았다면 패스)
git clone 
cd otp-ai

# 2. 가상환경 생성 및 활성화 (강력 추천 - 의존성 꼬임 방지)
python3 -m venv venv
source venv/bin/activate
```

### 2. 필수 라이브러리 설치

`requirements.txt`가 없어도 됩니다. 아래 한 줄이면 충분합니다.

```bash
pip install modal
```

### 3. Modal 계정 연동 (무료 크레딧 사용)

본인의 깃허브 계정으로 Modal에 가입하고 로컬 터미널과 연결합니다. (월 $30 무료 크레딧 제공)

```bash
modal token new
```

위 명령어를 치면 브라우저가 열립니다.

1. GitHub로 로그인하고 **Authorize** 버튼을 누르세요.
2. 터미널에 `Token created...` 메시지가 뜨면 성공입니다.

---

## 🧪 튜닝 및 테스트 방법 (핵심)

동영상 처리 로직(프레임 추출 간격, 스크롤 감도 등)을 수정하고 결과를 확인하는 방법입니다.

### 준비물

프로젝트 루트 폴더에 테스트용 파일이 있어야 합니다.

- `test_video.mp4` (필수)
- `test1.jpg` (옵션)

### 실행 방법 (서버 배포 X, 1회성 실행 O)

코드를 수정한 뒤, 터미널에 아래 명령어를 입력하면 즉시 클라우드 GPU에서 실행되고 결과가 출력됩니다.

```bash
# deploy.py 맨 밑에 있는 main() 함수가 실행됩니다.
modal run deploy.py
```

### ⚙️ 튜닝 포인트 (deploy.py)

파일 내 `VideoOCRService` 클래스 내부를 수정하며 최적값을 찾아주세요.

#### 1. `SKIP_FRAMES`: 몇 프레임마다 검사할지 설정 (현재 1로 설정됨)

- `0`: 모든 프레임 검사 (정확도 ↑, 속도 ↓)
- `1`: 1장 건너뛰고 검사 (밸런스)
- `2`: 2장 건너뛰고 검사 (속도 ↑, 정확도 ↓)

#### 2. `dy` 임계값 (코드 내 `0.6`): 스크롤이 얼마나 발생했을 때 캡처할지 설정

- `if abs(scroll_acc) > h * 0.6:` 부분 수정
- 숫자가 클수록 캡처가 적게 되고(놓칠 위험), 작으면 중복 캡처가 많아집니다.

---

## ⚠️ 주의사항 (필독)

### `modal deploy` 금지 (권장)

- `deploy`를 하면 본인 계정에 서버가 상시 등록되어 관리하기 귀찮아질 수 있습니다.
- 튜닝할 때는 **`modal run`**만 사용하세요. (개발용)
- 배포(Production)는 메인 관리자가 OCI 연동 계정으로 진행합니다.

### 빨간 줄 무시하세요

- VSCode에서 `import torch`, `from paddleocr ...` 부분에 빨간 밑줄이 그어져도 정상입니다.
- 로컬에는 안 깔려있지만, 실행되는 곳(클라우드)에는 다 깔려있습니다.
- **절대 로컬에 설치하려고 애쓰지 마세요.**

### 작업 흐름

1. `deploy.py` 수정
2. `modal run deploy.py`로 결과 확인
3. 만족스러우면 `git push`

